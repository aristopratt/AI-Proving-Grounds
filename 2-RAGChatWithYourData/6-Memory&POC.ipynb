{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conversational RAG Chatbot with Panel UI\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook builds an **interactive chatbot UI** using Panel that:\n",
        "1. Loads the DPDPA PDF into a vector database\n",
        "2. Provides conversational question answering with **memory** (chat history)\n",
        "3. Displays sources for transparency and citations\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Conversational Memory**: Remembers previous questions and answers in the session\n",
        "- **RAG Pipeline**: Retrieves relevant DPDPA sections before generating answers\n",
        "- **Panel UI**: Interactive web-based chat interface\n",
        "- **Source Attribution**: Shows which PDF pages were used for each answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import datetime\n",
        "import panel as pn\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "_ = load_dotenv(find_dotenv())\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "# Initialize Panel extension for interactive widgets\n",
        "pn.extension()\n",
        "\n",
        "# Select appropriate GPT model\n",
        "current_date = datetime.datetime.now().date()\n",
        "if current_date < datetime.date(2023, 9, 2):\n",
        "    llm_name = \"gpt-3.5-turbo-0301\"\n",
        "else:\n",
        "    llm_name = \"gpt-3.5-turbo\"\n",
        "print(f\"Using model: {llm_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Document loading and processing\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Embeddings and Vector Store\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "# LLM and Chains\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_classic.chains import ConversationalRetrievalChain\n",
        "from langchain_classic.memory import ConversationBufferMemory\n",
        "\n",
        "# Prompts\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Database Function\n",
        "\n",
        "This function:\n",
        "1. Loads a PDF file\n",
        "2. Splits it into chunks\n",
        "3. Creates embeddings and stores them in a vector database\n",
        "4. Returns a ConversationalRetrievalChain with memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_db(file, chain_type, k):\n",
        "    \"\"\"\n",
        "    Load PDF, create vector database, and return conversational QA chain.\n",
        "    \n",
        "    Args:\n",
        "        file: Path to PDF file\n",
        "        chain_type: Chain type for retrieval ('stuff', 'map_reduce', 'refine')\n",
        "        k: Number of documents to retrieve\n",
        "    \n",
        "    Returns:\n",
        "        ConversationalRetrievalChain with memory\n",
        "    \"\"\"\n",
        "    # Load PDF documents\n",
        "    loader = PyPDFLoader(file)\n",
        "    documents = loader.load()\n",
        "    \n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000, \n",
        "        chunk_overlap=150\n",
        "    )\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    \n",
        "    # Create embeddings and vector database\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
        "    \n",
        "    # Create retriever\n",
        "    retriever = db.as_retriever(\n",
        "        search_type=\"similarity\", \n",
        "        search_kwargs={\"k\": k}\n",
        "    )\n",
        "    \n",
        "    # Create conversational memory\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key=\"chat_history\",\n",
        "        return_messages=True,\n",
        "        output_key='answer'\n",
        "    )\n",
        "    \n",
        "    # Create LLM\n",
        "    llm = ChatOpenAI(\n",
        "        model=llm_name,\n",
        "        temperature=0\n",
        "    )\n",
        "    \n",
        "    # Create conversational retrieval chain\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=retriever,\n",
        "        memory=memory,\n",
        "        return_source_documents=True,\n",
        "        chain_type=chain_type\n",
        "    )\n",
        "    \n",
        "    return qa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Panel Chatbot UI Class\n",
        "\n",
        "This class creates an interactive chat interface with:\n",
        "- File upload capability\n",
        "- Database loading button\n",
        "- Chat interface with memory\n",
        "- Source document display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class cbfs(pn.viewable.Viewer):\n",
        "    \"\"\"\n",
        "    Conversational Chatbot with File System (cbfs)\n",
        "    \n",
        "    A Panel-based chatbot UI for RAG with conversational memory.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, **params):\n",
        "        super(cbfs, self).__init__(**params)\n",
        "        \n",
        "        # Initialize state\n",
        "        self.panels = []\n",
        "        self.loaded_file = \"./99-DPDPA.pdf\"\n",
        "        self.qa = None\n",
        "        \n",
        "        # Create widgets\n",
        "        self.file_input = pn.widgets.FileInput(\n",
        "            accept='.pdf',\n",
        "            name='Upload PDF'\n",
        "        )\n",
        "        \n",
        "        self.button_load = pn.widgets.Button(\n",
        "            name=\"Load Database\", \n",
        "            button_type='primary'\n",
        "        )\n",
        "        self.button_load.on_click(self.load_db_click)\n",
        "        \n",
        "        self.button_clear = pn.widgets.Button(\n",
        "            name=\"Clear Chat History\", \n",
        "            button_type='warning'\n",
        "        )\n",
        "        self.button_clear.on_click(self.clear_history)\n",
        "        \n",
        "        self.inp = pn.widgets.TextInput(\n",
        "            placeholder='Ask a question about the DPDPA...'\n",
        "        )\n",
        "        self.inp.param.watch(self.qa_callback, 'value')\n",
        "        \n",
        "        self.bound_button_load = pn.bind(\n",
        "            self.load_db_click, \n",
        "            self.button_load.param.clicks\n",
        "        )\n",
        "        \n",
        "        # Info panel\n",
        "        self.info_panel = pn.pane.Markdown(\n",
        "            \"**Status:** Click 'Load Database' to start\",\n",
        "            styles={'background-color': '#F6F6F6', 'padding': '10px'}\n",
        "        )\n",
        "        \n",
        "        # Chat display area - dynamic column that updates with chat history\n",
        "        self.chat_display = pn.Column()\n",
        "        \n",
        "    def load_db_click(self, event=None):\n",
        "        \"\"\"Load the database when button is clicked\"\"\"\n",
        "        try:\n",
        "            self.info_panel.object = \"**Status:** Loading database...\"\n",
        "            \n",
        "            # Load the QA chain\n",
        "            self.qa = load_db(self.loaded_file, \"stuff\", 4)\n",
        "            \n",
        "            self.info_panel.object = f\"**Status:** âœ… Database loaded from {self.loaded_file}. Ask questions below!\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.info_panel.object = f\"**Status:** âŒ Error loading database: {str(e)}\"\n",
        "    \n",
        "    def qa_callback(self, event):\n",
        "        \"\"\"Process user question and display answer\"\"\"\n",
        "        question = event.new\n",
        "        \n",
        "        if not question or self.qa is None:\n",
        "            return\n",
        "        \n",
        "        try:\n",
        "            # Get answer from conversational chain\n",
        "            result = self.qa({\"question\": question})\n",
        "            \n",
        "            # Extract answer and sources\n",
        "            answer = result['answer']\n",
        "            source_docs = result.get('source_documents', [])\n",
        "            \n",
        "            # Format sources\n",
        "            sources_text = \"\\n\\n**Sources:**\\n\"\n",
        "            if source_docs:\n",
        "                for i, doc in enumerate(source_docs[:3], 1):\n",
        "                    page = doc.metadata.get('page', 'N/A')\n",
        "                    sources_text += f\"- Page {page}: {doc.page_content[:150]}...\\n\"\n",
        "            else:\n",
        "                sources_text += \"No sources found.\"\n",
        "            \n",
        "            # Create chat message panels\n",
        "            self.panels.append(\n",
        "                pn.Row(\n",
        "                    pn.pane.Markdown(f\"**You:** {question}\", width=600),\n",
        "                    styles={'background-color': '#E8F4F8', 'padding': '10px'}\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            self.panels.append(\n",
        "                pn.Row(\n",
        "                    pn.pane.Markdown(f\"**Bot:** {answer}{sources_text}\", width=600),\n",
        "                    styles={'background-color': '#F0F0F0', 'padding': '10px'}\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            # Update the chat display\n",
        "            self.chat_display.objects = self.panels\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.panels.append(\n",
        "                pn.Row(\n",
        "                    pn.pane.Markdown(f\"**Error:** {str(e)}\", width=600),\n",
        "                    styles={'background-color': '#FFE6E6', 'padding': '10px'}\n",
        "                )\n",
        "            )\n",
        "            self.chat_display.objects = self.panels\n",
        "        \n",
        "        # Clear input\n",
        "        self.inp.value = ''\n",
        "    \n",
        "    def clear_history(self, event=None):\n",
        "        \"\"\"Clear chat history and memory\"\"\"\n",
        "        self.panels = []\n",
        "        self.chat_display.objects = []\n",
        "        if self.qa:\n",
        "            self.qa.memory.clear()\n",
        "        self.info_panel.object = \"**Status:** Chat history cleared. Database still loaded.\"\n",
        "    \n",
        "    def __panel__(self):\n",
        "        \"\"\"Return the Panel layout\"\"\"\n",
        "        return pn.Column(\n",
        "            pn.pane.Markdown(\"# ðŸ¤– DPDPA Chatbot with RAG + Memory\"),\n",
        "            pn.Row(self.button_load, self.button_clear),\n",
        "            self.info_panel,\n",
        "            pn.layout.Divider(),\n",
        "            self.chat_display,\n",
        "            self.inp,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize and Display Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5b7d844eced484db4fc8549b8373817",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BokehModel(combine_events=True, render_bundle={'docs_json': {'afb2f508-4cfe-4fa8-b42b-1e050b01b57b': {'versionâ€¦"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create chatbot instance\n",
        "cb = cbfs()\n",
        "\n",
        "# Display the chatbot UI\n",
        "cb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage Instructions\n",
        "\n",
        "1. **Load Database**: Click the \"Load Database\" button to load the DPDPA PDF into memory\n",
        "2. **Ask Questions**: Type your question in the text input and press Enter\n",
        "3. **Conversational Context**: The bot remembers previous questions and answers in the session\n",
        "4. **View Sources**: Each answer includes citations showing which PDF pages were used\n",
        "5. **Clear History**: Click \"Clear Chat History\" to reset the conversation (database remains loaded)\n",
        "\n",
        "## Example Questions\n",
        "\n",
        "- What are the penalties for a data breach?\n",
        "- Who is a Data Fiduciary?\n",
        "- What are the obligations of a Data Fiduciary?\n",
        "- How should consent be obtained?\n",
        "- What rights do Data Principals have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the QA System Directly (Optional)\n",
        "\n",
        "You can also test the QA chain directly without the UI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pratt/technologia/ai-proving-grounds/.venv/lib/python3.12/site-packages/docarray/helper.py:255: SyntaxWarning: invalid escape sequence '\\*'\n",
            "  e.g. '\\*.py', '[\\*.zip, \\*.gz]'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: The penalties for a data breach can extend up to two hundred and fifty crore rupees, as specified in the Schedule mentioned in the Act. The amount of monetary penalty imposed is determined by factors such as the nature, gravity, and duration of the breach, the type of personal data affected, any gains or losses realized by the person, actions taken to mitigate the breach, and the overall impact of the penalty on the person. Additionally, if the Board imposes monetary penalties on a Data Fiduciary in multiple instances, they may advise blocking access to certain information in the interests of the general public.\n",
            "\n",
            "Sources:\n",
            "1. Page 13: personal data breach, and to inquire into such personal data breach and impose\n",
            "penalty as provided i...\n",
            "2. Page 20: SEC. 1] THE GAZETTE OF INDIA EXTRAORDINARY 21\n",
            "Breach of provisions of  this Act or rules made thereu...\n"
          ]
        }
      ],
      "source": [
        "# Load QA chain directly\n",
        "qa_chain = load_db(\"./99-DPDPA.pdf\", \"stuff\", 4)\n",
        "\n",
        "# Ask a question\n",
        "result = qa_chain({\"question\": \"What are the penalties for a data breach?\"})\n",
        "\n",
        "print(\"Answer:\", result['answer'])\n",
        "print(\"\\nSources:\")\n",
        "for i, doc in enumerate(result['source_documents'][:2], 1):\n",
        "    print(f\"{i}. Page {doc.metadata.get('page', 'N/A')}: {doc.page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Conversational Memory\n",
        "\n",
        "The key feature of this chatbot is **memory** - it remembers previous exchanges:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1: A Data Fiduciary is defined as any person who alone or in conjunction with others determines the purpose and means of processing personal data. They are responsible for complying with data protection regulations and ensuring the security and accuracy of personal data they process.\n",
            "\n",
            "Q2: The main obligations of a Data Fiduciary include:\n",
            "1. Complying with the provisions of the data protection Act and rules made thereunder.\n",
            "2. Being responsible for processing undertaken by itself or on its behalf by a Data Processor.\n",
            "3. Engaging Data Processors only under a valid contract for offering goods or services to Data Principals.\n",
            "4. Ensuring completeness, accuracy, and consistency of personal data used in decision-making or disclosed to another Data Fiduciary.\n",
            "5. Implementing appropriate technical and organizational measures for compliance.\n",
            "6. Protecting personal data in its possession or control with reasonable security safeguards.\n",
            "7. Notifying the Board and affected Data Principals in case of a personal data breach.\n",
            "8. Erasing personal data upon Data Principal's withdrawal of consent unless retention is necessary for legal compliance.\n"
          ]
        }
      ],
      "source": [
        "# First question\n",
        "result1 = qa_chain({\"question\": \"What is a Data Fiduciary?\"})\n",
        "print(\"Q1:\", result1['answer'])\n",
        "\n",
        "# Follow-up question (uses memory)\n",
        "result2 = qa_chain({\"question\": \"What are their main obligations?\"})\n",
        "print(\"\\nQ2:\", result2['answer'])\n",
        "\n",
        "# The bot knows \"their\" refers to \"Data Fiduciary\" from the previous question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
