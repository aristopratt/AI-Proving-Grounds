{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6976a145",
      "metadata": {},
      "source": [
        "# Document Loading for RAG Systems\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates **document loading strategies** for building RAG (Retrieval Augmented Generation) applications. Loading is the first critical step in the RAG pipeline:\n",
        "\n",
        "```\n",
        "Load → Split → Embed → Store → Retrieve → Generate\n",
        "```\n",
        "\n",
        "## Why Document Loading Matters\n",
        "\n",
        "1. **Data Diversity**: RAG systems need to ingest multiple formats (PDFs, videos, wikis, APIs)\n",
        "2. **Metadata Preservation**: Source tracking enables citation and audit trails\n",
        "3. **Batch Processing**: Efficient loading reduces pipeline latency\n",
        "4. **Content Extraction**: Proper parsing ensures high-quality text for embedding\n",
        "\n",
        "## What We'll Cover\n",
        "\n",
        "1. **PDF Loading** - Extracting text and metadata from PDF documents\n",
        "2. **YouTube Audio** - Transcribing video content with OpenAI Whisper\n",
        "3. **Generic Loaders** - Flexible patterns for custom data sources\n",
        "4. **Metadata Management** - Tracking provenance for retrieved content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8282c4bb",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Initialize OpenAI client and load environment variables. These credentials are needed for:\n",
        "- OpenAI Whisper API (audio transcription)\n",
        "- Token counting with tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f9238cbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import tiktoken  # OpenAI's tokenizer for token counting\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# Load environment variables from .env file (must contain OPENAI_API_KEY)\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78558334",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## PDF Document Loading\n",
        "\n",
        "### PyPDFLoader\n",
        "\n",
        "LangChain's `PyPDFLoader` provides:\n",
        "- **Page-by-page parsing** - Each page becomes a separate Document object\n",
        "- **Metadata extraction** - PDF properties (creator, creation date, page numbers)\n",
        "- **Text extraction** - Uses pypdf library under the hood\n",
        "\n",
        "### Use Cases\n",
        "- Legal documents (contracts, legislation)\n",
        "- Research papers and technical documentation\n",
        "- Reports and policy documents\n",
        "\n",
        "### Example: Indian Data Protection Act (DPDPA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ef6e570e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load PDF - Digital Personal Data Protection Act (India, 2023)\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"./99-DPDPA.pdf\")\n",
        "pages = loader.load()  # Returns list of Document objects (one per page)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afb62500",
      "metadata": {},
      "source": [
        "### Verify Document Count\n",
        "\n",
        "Check how many pages were loaded from the PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "153f4445",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count total pages in PDF\n",
        "len(pages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c21ff149",
      "metadata": {},
      "source": [
        "**Result**: 21 pages extracted from the PDF.\n",
        "\n",
        "---\n",
        "\n",
        "## Inspecting Document Structure\n",
        "\n",
        "Each `Document` object contains:\n",
        "- `page_content`: Extracted text from the page\n",
        "- `metadata`: Dictionary with source info, page numbers, PDF properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "59f04dc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select first page for inspection\n",
        "page = pages[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f5bfa9",
      "metadata": {},
      "source": [
        "### Preview Page Content\n",
        "\n",
        "Display first 500 characters to verify text extraction quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fa39cb92",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE DIGITAL PERSONAL DATA PROTECTION ACT, 2023\n",
            "(NO. 22 OF 2023)\n",
            "[11th August, 2023.]\n",
            "An Act to provide for the processing of digital personal data in a manner that\n",
            "recognises both the right of individuals to protect their personal data and the\n",
            "need to process such personal data for lawful purposes and for matters\n",
            "connected therewith or incidental thereto.\n",
            "BE it enacted by Parliament in the Seventy-fourth Year of the Republic of India as\n",
            "follows:––\n",
            "CHAPTER I\n",
            "PRELIMINARY\n",
            "1. (1) This Act may be cal\n"
          ]
        }
      ],
      "source": [
        "# Print first 500 characters of page content\n",
        "print(page.page_content[0:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257ba615",
      "metadata": {},
      "source": [
        "**Observation**: Clean text extraction from Act title, date, and preamble.\n",
        "\n",
        "---\n",
        "\n",
        "## Metadata Inspection\n",
        "\n",
        "Metadata enables:\n",
        "1. **Citation** - Reference source page in generated responses\n",
        "2. **Filtering** - Retrieve only from specific documents/pages\n",
        "3. **Audit Trail** - Track which sources influenced LLM output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0e972f2a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'producer': 'iTextSharp™ 5.5.13.1 ©2000-2019 iText Group NV (AGPL-version)',\n",
              " 'creator': 'PyPDF',\n",
              " 'creationdate': '2023-08-12T02:13:03+05:30',\n",
              " 'moddate': '2023-08-12T02:14:35+05:30',\n",
              " 'source': './99-DPDPA.pdf',\n",
              " 'total_pages': 21,\n",
              " 'page': 0,\n",
              " 'page_label': '1'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspect metadata dictionary\n",
        "page.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d115f105",
      "metadata": {},
      "source": [
        "**Metadata Fields**:\n",
        "- `source`: File path\n",
        "- `page`: Zero-indexed page number (0 = first page)\n",
        "- `page_label`: Human-readable page number from PDF\n",
        "- `total_pages`: Total document length\n",
        "- `producer`, `creator`: PDF generation tools\n",
        "- `creationdate`, `moddate`: Document timestamps\n",
        "\n",
        "This rich metadata is critical for production RAG systems requiring provenance tracking.\n",
        "\n",
        "---\n",
        "\n",
        "## YouTube Audio Loading & Transcription\n",
        "\n",
        "### Use Case: Video Content as Knowledge Base\n",
        "\n",
        "Many organizations have knowledge in video format:\n",
        "- Training videos and tutorials\n",
        "- Conference talks and lectures\n",
        "- Product demos and webinars\n",
        "\n",
        "**Challenge**: Video content is unsearchable unless transcribed.\n",
        "\n",
        "**Solution**: LangChain's `YoutubeAudioLoader` + `OpenAIWhisperParser` pipeline.\n",
        "\n",
        "### Architecture\n",
        "\n",
        "```\n",
        "YouTube URL → Download Audio (yt-dlp) → Transcribe (Whisper API) → Document\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c3ba3eeb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import YouTube audio loading components\n",
        "from langchain_community.document_loaders.generic import GenericLoader, FileSystemBlobLoader\n",
        "from langchain_community.document_loaders.parsers import OpenAIWhisperParser\n",
        "from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83dbfa67",
      "metadata": {},
      "source": [
        "### Component Breakdown\n",
        "\n",
        "1. **YoutubeAudioLoader**: Downloads audio using `yt-dlp`\n",
        "2. **OpenAIWhisperParser**: Transcribes audio via Whisper API\n",
        "3. **GenericLoader**: Orchestrates blob loading → parsing pipeline\n",
        "4. **FileSystemBlobLoader**: Alternative for pre-downloaded audio files\n",
        "\n",
        "### Example: Stanford CS229 Lecture\n",
        "\n",
        "Loading Andrew Ng's Machine Learning lecture (Autumn 2018)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "429fcbf6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Stanford CS229 Lecture 1 - Andrew Ng\n",
        "# url = \"https://www.youtube.com/watch?v=Rj5M_c5mgk8\"\n",
        "# save_dir = \"docs/youtube/\"\n",
        "\n",
        "# # GenericLoader orchestrates: Blob Loader → Parser\n",
        "# loader = GenericLoader(\n",
        "#     YoutubeAudioLoader([url], save_dir),  # Download audio via yt-dlp\n",
        "#     # FileSystemBlobLoader(save_dir, glob=\"*.m4a\"),  # Alternative: load pre-downloaded files\n",
        "#     OpenAIWhisperParser()  # Transcribe audio via OpenAI Whisper API\n",
        "# )\n",
        "\n",
        "# # This will: 1) Download audio, 2) Send to Whisper API, 3) Return transcribed text\n",
        "# docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6fe6ed",
      "metadata": {},
      "source": [
        "### Process Breakdown\n",
        "\n",
        "**Step 1**: `YoutubeAudioLoader` downloads audio\n",
        "- Uses `yt-dlp` (must be installed: see [README](../README.md))\n",
        "- Requires `ffmpeg` for audio extraction\n",
        "- Saves to `docs/youtube/` directory\n",
        "\n",
        "**Step 2**: `OpenAIWhisperParser` transcribes\n",
        "- Sends audio to OpenAI Whisper API\n",
        "- Handles long audio via chunking (25MB limit per request)\n",
        "- Returns text with timestamps (optional)\n",
        "\n",
        "**Step 3**: Returns Document objects\n",
        "- `page_content`: Full transcription text\n",
        "- `metadata`: Source URL, video title, duration\n",
        "\n",
        "**Note**: This process can take several minutes for long videos + uses OpenAI API credits.\n",
        "\n",
        "---\n",
        "\n",
        "## Inspect Transcription Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5f2aff76",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview first 500 characters of transcription\n",
        "# docs[0].page_content[0:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f54411",
      "metadata": {},
      "source": [
        "**Result**: High-quality transcription of lecture audio, including speaker introductions and lecture content.\n",
        "\n",
        "### Production Considerations\n",
        "\n",
        "1. **Caching**: Audio files are saved locally - rerunning uses cached files (fast)\n",
        "2. **Cost**: Whisper API charges ~$0.006/minute of audio\n",
        "3. **Accuracy**: Whisper handles technical terminology well (CS/ML lectures)\n",
        "4. **Batch Processing**: Use `FileSystemBlobLoader` for bulk transcription of downloaded files\n",
        "\n",
        "---\n",
        "\n",
        "## Web Content Loading\n",
        "\n",
        "### WebBaseLoader\n",
        "\n",
        "Load content directly from URLs - useful for:\n",
        "- Documentation pages\n",
        "- Blog posts and articles\n",
        "- GitHub README files\n",
        "- Wiki pages\n",
        "\n",
        "**Example**: Loading Basecamp's engineering handbook from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "41528c93",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# Load web content via HTTP request\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Example: Basecamp's programmer title ladder (GitHub markdown)\n",
        "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/titles-for-programmers.md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "513adb87",
      "metadata": {},
      "source": [
        "### How WebBaseLoader Works\n",
        "\n",
        "1. **HTTP Request**: Fetches HTML content via requests library\n",
        "2. **HTML Parsing**: Uses BeautifulSoup to extract text\n",
        "3. **Cleaning**: Removes scripts, styles, navigation elements\n",
        "4. **Document Creation**: Returns clean text with URL metadata\n",
        "\n",
        "**Limitations**:\n",
        "- JavaScript-rendered content requires Selenium (see `SeleniumURLLoader`)\n",
        "- Rate limiting may block frequent requests\n",
        "- Some sites require authentication\n",
        "\n",
        "---\n",
        "\n",
        "## Load and Inspect Web Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "031cbc9c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhandbook/titles-for-programmers.md at master · basecamp/handbook · GitHub\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n \\n\\n\\nAppearance settings\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPlatformAI CODE CREATIONGitHub CopilotWrite better code with AIGitHub SparkBuild and deploy intelligent appsGitHub ModelsManage and compare '"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fetch and parse the web page\n",
        "docs = loader.load()\n",
        "\n",
        "# Preview extracted text content\n",
        "docs[0].page_content[0:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74761898",
      "metadata": {},
      "source": [
        "**Result**: Clean markdown content extracted from GitHub page, including title structure and job descriptions.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary: Document Loading Best Practices\n",
        "\n",
        "### Loader Selection Guide\n",
        "\n",
        "| Content Type | Loader | Key Benefits |\n",
        "|-------------|--------|--------------|\n",
        "| **PDFs** | `PyPDFLoader` | Page-level metadata, reliable extraction |\n",
        "| **Videos/Audio** | `YoutubeAudioLoader` + `OpenAIWhisperParser` | High-quality transcription, handles technical content |\n",
        "| **Web Pages** | `WebBaseLoader` | Simple HTTP-based loading, good for static sites |\n",
        "| **Notion** | `NotionDirectoryLoader` | Preserves block structure, exports workspace |\n",
        "| **GitHub** | `GitHubIssuesLoader`, `GitHubRepositoryLoader` | Issue tracking, code documentation |\n",
        "| **APIs** | `APILoader`, custom loaders | Real-time data integration |\n",
        "\n",
        "### Production Checklist\n",
        "\n",
        "1. **Error Handling**: Wrap loaders in try/catch for missing files, network failures\n",
        "2. **Metadata Enrichment**: Add custom fields (department, category, timestamp)\n",
        "3. **Caching**: Store loaded documents to avoid redundant API calls\n",
        "4. **Batch Processing**: Process large document sets asynchronously\n",
        "5. **Content Validation**: Check for empty documents, extraction failures\n",
        "6. **Cost Tracking**: Monitor API usage (Whisper, web scraping limits)\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Once documents are loaded:\n",
        "1. **Split** into chunks (see `2-DocumentSplitting.ipynb`)\n",
        "2. **Embed** using text embeddings (OpenAI, Cohere, etc.)\n",
        "3. **Store** in vector database (Pinecone, Weaviate, Chroma)\n",
        "4. **Retrieve** relevant chunks for LLM context\n",
        "5. **Generate** responses with citations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7429f1f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
