{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dbf5046c",
      "metadata": {},
      "source": [
        "# Chain-of-Thought (CoT) Reasoning\n",
        "\n",
        "## Overview\n",
        "\n",
        "**Chain-of-Thought prompting** improves LLM accuracy on complex tasks by eliciting step-by-step reasoning. This technique is critical for:\n",
        "\n",
        "1. **Multi-Step Problems** - Math, logic, troubleshooting\n",
        "2. **Fact-Checking** - Verify assumptions against data\n",
        "3. **Policy Interpretation** - Complex rule-based decisions\n",
        "4. **Debugging** - Understand LLM's reasoning process\n",
        "\n",
        "## Why CoT Matters\n",
        "\n",
        "### Accuracy Improvements\n",
        "- **Math Problems**: 50-80% accuracy gain\n",
        "- **Logic Puzzles**: 40-60% improvement  \n",
        "- **Multi-Step Reasoning**: 30-50% better results\n",
        "\n",
        "### Transparency\n",
        "- See **how** the LLM reached its conclusion\n",
        "- Debug incorrect outputs\n",
        "- Build user trust with explainability\n",
        "\n",
        "## Two CoT Patterns\n",
        "\n",
        "### 1. Visible Reasoning\n",
        "Show step-by-step thinking to the user (educational, transparency)\n",
        "\n",
        "### 2. Inner Monologue (This Notebook)\n",
        "Hide reasoning steps, show only final answer (better UX, cleaner responses)\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "### Structured Prompts\n",
        "Break tasks into numbered steps with clear instructions\n",
        "\n",
        "### Delimiter Separation\n",
        "Use markers (e.g., `####`) to separate reasoning from answer\n",
        "\n",
        "### Inner Monologue\n",
        "LLM reasons internally, user sees only final output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cee9005",
      "metadata": {},
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f27aca55",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd5748c",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Structured CoT System Message\n",
        "\n",
        "This system message implements a **5-step reasoning process** for customer service queries:\n",
        "\n",
        "### Step-by-Step Breakdown\n",
        "\n",
        "1. **Classify Intent** - Is user asking about specific products?\n",
        "2. **Validate Products** - Are mentioned products in our catalog?\n",
        "3. **Extract Assumptions** - What is the user assuming? (e.g., price comparison)\n",
        "4. **Fact-Check** - Are assumptions correct based on product data?\n",
        "5. **Respond** - Correct misconceptions, answer question\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Product Catalog** - Embedded in system message (5 laptops)\n",
        "- **Delimiter Format** - Forces structured output: `Step 1:#### ... Step 2:#### ...`\n",
        "- **Error Correction** - Identifies and fixes user misconceptions\n",
        "- **Tone Control** - \"Polite and friendly\" specified\n",
        "\n",
        "**Production Note**: In real systems, product data comes from database/API, not embedded in prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d937f862",
      "metadata": {},
      "outputs": [],
      "source": [
        "client = openai.OpenAI()\n",
        "\n",
        "def get_completion_from_messages(\n",
        "    messages,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    max_tokens=500,\n",
        "):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdaccfb3",
      "metadata": {},
      "source": [
        "## Test Case 1: Price Comparison with False Assumption\n",
        "\n",
        "User assumes Chromebook ($249.99) is MORE expensive than Desktop ($999.99) - **incorrect**.\n",
        "\n",
        "CoT will:\n",
        "1. Identify the two products\n",
        "2. Detect the false assumption\n",
        "3. Correct it politely\n",
        "4. Provide accurate price comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63359be",
      "metadata": {},
      "outputs": [],
      "source": [
        "delimiter = \"####\"\n",
        "system_message = f\"\"\"\n",
        "Follow these steps to answer the customer queries.\n",
        "The customer query will be delimited with four hashtags,\\\n",
        "i.e. {delimiter}. \n",
        "\n",
        "Step 1:{delimiter} First decide whether the user is \\\n",
        "asking a question about a specific product or products. \\\n",
        "Product cateogry doesn't count. \n",
        "\n",
        "Step 2:{delimiter} If the user is asking about \\\n",
        "specific products, identify whether \\\n",
        "the products are in the following list.\n",
        "All available products: \n",
        "1. Product: TechPro Ultrabook\n",
        "   Category: Computers and Laptops\n",
        "   Brand: TechPro\n",
        "   Model Number: TP-UB100\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.5\n",
        "   Features: 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\n",
        "   Description: A sleek and lightweight ultrabook for everyday use.\n",
        "   Price: $799.99\n",
        "\n",
        "2. Product: BlueWave Gaming Laptop\n",
        "   Category: Computers and Laptops\n",
        "   Brand: BlueWave\n",
        "   Model Number: BW-GL200\n",
        "   Warranty: 2 years\n",
        "   Rating: 4.7\n",
        "   Features: 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\n",
        "   Description: A high-performance gaming laptop for an immersive experience.\n",
        "   Price: $1199.99\n",
        "\n",
        "3. Product: PowerLite Convertible\n",
        "   Category: Computers and Laptops\n",
        "   Brand: PowerLite\n",
        "   Model Number: PL-CV300\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.3\n",
        "   Features: 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\n",
        "   Description: A versatile convertible laptop with a responsive touchscreen.\n",
        "   Price: $699.99\n",
        "\n",
        "4. Product: TechPro Desktop\n",
        "   Category: Computers and Laptops\n",
        "   Brand: TechPro\n",
        "   Model Number: TP-DT500\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.4\n",
        "   Features: Intel Core i7 processor, 16GB RAM, 1TB HDD, NVIDIA GeForce GTX 1660\n",
        "   Description: A powerful desktop computer for work and play.\n",
        "   Price: $999.99\n",
        "\n",
        "5. Product: BlueWave Chromebook\n",
        "   Category: Computers and Laptops\n",
        "   Brand: BlueWave\n",
        "   Model Number: BW-CB100\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.1\n",
        "   Features: 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\n",
        "   Description: A compact and affordable Chromebook for everyday tasks.\n",
        "   Price: $249.99\n",
        "\n",
        "Step 3:{delimiter} If the message contains products \\\n",
        "in the list above, list any assumptions that the \\\n",
        "user is making in their \\\n",
        "message e.g. that Laptop X is bigger than \\\n",
        "Laptop Y, or that Laptop Z has a 2 year warranty.\n",
        "\n",
        "Step 4:{delimiter}: If the user made any assumptions, \\\n",
        "figure out whether the assumption is true based on your \\\n",
        "product information. \n",
        "\n",
        "Step 5:{delimiter}: First, politely correct the \\\n",
        "customer's incorrect assumptions if applicable. \\\n",
        "Only mention or reference products in the list of \\\n",
        "5 available products, as these are the only 5 \\\n",
        "products that the store sells. \\\n",
        "Answer the customer in a friendly tone.\n",
        "\n",
        "Use the following format:\n",
        "Step 1:{delimiter} <step 1 reasoning>\n",
        "Step 2:{delimiter} <step 2 reasoning>\n",
        "Step 3:{delimiter} <step 3 reasoning>\n",
        "Step 4:{delimiter} <step 4 reasoning>\n",
        "Response to user:{delimiter} <response to customer>\n",
        "\n",
        "Make sure to include {delimiter} to separate every step.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41d21b0",
      "metadata": {},
      "source": [
        "**Expected Response** (with reasoning steps visible):\n",
        "```\n",
        "Step 1:#### User is asking about specific products\n",
        "Step 2:#### Both products exist in catalog\n",
        "Step 3:#### User assumes Chromebook is more expensive  \n",
        "Step 4:#### Assumption is FALSE (Chromebook $249.99 < Desktop $999.99)\n",
        "Response to user:#### Actually, the BlueWave Chromebook is $750 LESS expensive than the TechPro Desktop...\n",
        "```\n",
        "\n",
        "**Key Benefit**: CoT catches the reversed assumption and corrects it.\n",
        "\n",
        "---\n",
        "\n",
        "## Test Case 2: Out-of-Scope Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63bd5e14",
      "metadata": {},
      "outputs": [],
      "source": [
        "user_message = f\"\"\"\n",
        "by how much is the BlueWave Chromebook more expensive \\\n",
        "than the TechPro Desktop\"\"\"\n",
        "\n",
        "messages =  [  \n",
        "{'role':'system', \n",
        " 'content': system_message},    \n",
        "{'role':'user', \n",
        " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
        "] \n",
        "\n",
        "response = get_completion_from_messages(messages, \"gpt-3.5-turbo\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2f97f5a",
      "metadata": {},
      "source": [
        "**Expected Response**:\n",
        "```\n",
        "Step 1:#### Not asking about specific products\n",
        "Step 2:#### N/A\n",
        "Step 3:#### N/A\n",
        "Step 4:#### N/A\n",
        "Response to user:#### No, we don't sell TVs. We specialize in computers and laptops.\n",
        "```\n",
        "\n",
        "**Key Benefit**: CoT determines question is off-topic, responds accordingly.\n",
        "\n",
        "---\n",
        "\n",
        "## Inner Monologue: Hiding Reasoning Steps\n",
        "\n",
        "The full CoT reasoning (Steps 1-4) is useful for debugging but clutters the user experience.\n",
        "\n",
        "**Solution**: Extract only the final response using delimiter splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce60e409",
      "metadata": {},
      "outputs": [],
      "source": [
        "user_message = f\"\"\"\n",
        "do you sell tvs\"\"\"\n",
        "messages =  [  \n",
        "{'role':'system', \n",
        " 'content': system_message},    \n",
        "{'role':'user', \n",
        " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
        "] \n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "930d9718",
      "metadata": {},
      "source": [
        "Inner Monologue\n",
        "Since we asked the LLM to separate its reasoning steps by a delimiter, we can hide the chain-of-thought reasoning from the final output that the user sees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a23390",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract only the final response (after last delimiter)\n",
        "try:\n",
        "    final_response = response.split(delimiter)[-1].strip()\n",
        "except Exception as e:\n",
        "    # Fallback if parsing fails\n",
        "    final_response = \"Sorry, I'm having trouble right now, please try asking another question.\"\n",
        "    \n",
        "print(final_response)  # User sees ONLY this, reasoning hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1533ad08",
      "metadata": {},
      "source": [
        "**Result**: Clean, user-friendly response without intermediate reasoning steps.\n",
        "\n",
        "---\n",
        "\n",
        "## Production Implementation Patterns\n",
        "\n",
        "### Complete CoT Pipeline\n",
        "\n",
        "```python\n",
        "def process_with_cot(user_query, product_catalog):\n",
        "    # 1. Build CoT system message\n",
        "    system_message = f\\\"\\\"\\\"\n",
        "    Follow these steps:\n",
        "    Step 1: Identify intent\n",
        "    Step 2: Validate against catalog\n",
        "    Step 3: Extract assumptions\n",
        "    Step 4: Fact-check assumptions\n",
        "    Response to user: Final answer\n",
        "    \n",
        "    Use delimiter {delimiter} between steps.\n",
        "    \n",
        "    Product Catalog:\n",
        "    {product_catalog}\n",
        "    \\\"\\\"\\\"\n",
        "    \n",
        "    # 2. Get full reasoning\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': f\"{delimiter}{user_query}{delimiter}\"}\n",
        "    ]\n",
        "    full_response = get_completion_from_messages(messages)\n",
        "    \n",
        "    # 3. Log full reasoning (for debugging/auditing)\n",
        "    log_cot_reasoning(user_query, full_response)\n",
        "    \n",
        "    # 4. Extract final answer for user\n",
        "    final_answer = extract_final_response(full_response, delimiter)\n",
        "    \n",
        "    return final_answer\n",
        "```\n",
        "\n",
        "### When to Use CoT\n",
        "\n",
        "| Task Type | Use CoT? | Reasoning |\n",
        "|-----------|----------|-----------|\n",
        "| Simple FAQ | ❌ No | Overhead not justified |\n",
        "| Math calculations | ✅ Yes | Accuracy critical |\n",
        "| Multi-step troubleshooting | ✅ Yes | Needs structured thinking |\n",
        "| Policy interpretation | ✅ Yes | Must verify compliance |\n",
        "| Creative writing | ❌ No | Constrains creativity |\n",
        "| Product recommendations | ✅ Yes | Compare multiple criteria |\n",
        "\n",
        "### Cost Considerations\n",
        "\n",
        "**Token Overhead**:\n",
        "- CoT adds ~100-200 tokens per request (reasoning steps)\n",
        "- Cost: ~$0.0001-0.0002 per request (gpt-3.5-turbo)\n",
        "\n",
        "**Worth It When**:\n",
        "- Accuracy gain > 20%\n",
        "- User questions are complex\n",
        "- Debugging/auditing is important\n",
        "\n",
        "**Not Worth It When**:\n",
        "- Simple lookups\n",
        "- High-volume, low-complexity queries\n",
        "- Cost sensitivity outweighs accuracy\n",
        "\n",
        "### Debugging with CoT\n",
        "\n",
        "```python\n",
        "# Development: Show full reasoning\n",
        "if DEBUG_MODE:\n",
        "    print(\"=== CoT Reasoning ===\")\n",
        "    print(full_response)\n",
        "    print(\"=== Final Response ===\")\n",
        "    print(final_answer)\n",
        "\n",
        "# Production: Log reasoning to analytics\n",
        "analytics.log_cot({\n",
        "    \"user_query\": user_query,\n",
        "    \"reasoning\": full_response,\n",
        "    \"final_answer\": final_answer,\n",
        "    \"timestamp\": datetime.now()\n",
        "})\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Advanced CoT Techniques\n",
        "\n",
        "### 1. Few-Shot CoT\n",
        "Provide examples of correct reasoning:\n",
        "\n",
        "```python\n",
        "system_message = \\\"\\\"\\\"\n",
        "Example 1:\n",
        "User: Is Product A cheaper than Product B?\n",
        "Step 1: Both products exist\n",
        "Step 2: A=$100, B=$200\n",
        "Step 3: User asks comparison\n",
        "Step 4: A < B, so yes\n",
        "Response: Yes, Product A ($100) is $100 cheaper.\n",
        "\n",
        "Now answer this query:\n",
        "{user_query}\n",
        "\\\"\\\"\\\"\n",
        "```\n",
        "\n",
        "### 2. Self-Consistency\n",
        "Generate multiple CoT reasoning paths, take majority vote:\n",
        "\n",
        "```python\n",
        "responses = [\n",
        "    get_completion_with_cot(query, temperature=0.7) \n",
        "    for _ in range(5)\n",
        "]\n",
        "final_answer = majority_vote(responses)\n",
        "```\n",
        "\n",
        "### 3. Least-to-Most Prompting\n",
        "Break complex problem into subproblems:\n",
        "\n",
        "```python\n",
        "# Step 1: List subproblems\n",
        "subproblems = get_completion(\"Break this into steps: {query}\")\n",
        "\n",
        "# Step 2: Solve each\n",
        "solutions = [solve(sub) for sub in subproblems]\n",
        "\n",
        "# Step 3: Combine\n",
        "final = combine_solutions(solutions)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Summary: CoT Best Practices\n",
        "\n",
        "### Implementation\n",
        "1. **Structure Steps Clearly** - Number them, define each purpose\n",
        "2. **Use Delimiters** - Separate reasoning from answer\n",
        "3. **Hide Reasoning** - Extract final response for UX\n",
        "4. **Log Full Output** - Keep for debugging/auditing\n",
        "5. **Error Handling** - Fallback if parsing fails\n",
        "\n",
        "### When to Use\n",
        "- ✅ Multi-step reasoning\n",
        "- ✅ Fact-checking required\n",
        "- ✅ Policy/rule interpretation\n",
        "- ✅ Debugging needed\n",
        "- ❌ Simple lookups\n",
        "- ❌ Creative/open-ended tasks\n",
        "\n",
        "### Performance\n",
        "- **Accuracy**: +30-80% on complex tasks\n",
        "- **Cost**: +50-100 tokens overhead\n",
        "- **Latency**: +0.5-1s (more thinking)\n",
        "\n",
        "### Next Steps\n",
        "- **E.PromptChaining** - Combine CoT with multi-step workflows\n",
        "- **F.EvaluatingOutputs** - Assess CoT reasoning quality\n",
        "- **G.CustomerServiceBot** - Integrate CoT into full system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23579a71",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
